{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.neighbors import KNeighborsRegressor, RadiusNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_data = pd.read_csv(\"newSourceOverall.csv\",index_col=False).drop(columns=[\"id\",\"short_name\", \"player_positions\", \"GK\"])\n",
    "# x_data = scaler.fit_transform(x_data)\n",
    "y_data = pd.read_csv(\"newTargetOverall.csv\")\n",
    "y_data = y_data.to_numpy() / 1000000\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.1, random_state=42)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {'n_neighbors': [*range(1, 50, 2)], \"p\": [1], \"metric\": [\"euclidean\"]}\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "model = GridSearchCV(knn, params, cv=5)\n",
    "model.fit(x_train, y_train)\n",
    "print(model.best_params_)\n",
    "\n",
    "rmse_val = []  #to store rmse values for different k\n",
    "for K in range(1, 100, 2):\n",
    "    model = KNeighborsRegressor(n_neighbors=K, metric='euclidean')\n",
    "\n",
    "    model.fit(x_train, y_train)  #fit the model\n",
    "    print(K, model.score(x_test, y_test))\n",
    "    predictions = model.predict(x_test)  #make prediction on test set\n",
    "    error = mean_absolute_error(y_test, predictions)\n",
    "    rmse_val.append(error)  #store rmse values\n",
    "\n",
    "#plotting the rmse values against k values\n",
    "curve = pd.DataFrame(rmse_val)  #elbow curve\n",
    "curve.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RadiusNeighborsRegressor()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omerk\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:470: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22660\\3926168698.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;31m# print(model.score(x_test, y_test))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m#make prediction on test set\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m \u001B[0merror\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmean_absolute_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[0mrmse_val\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m#store rmse values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001B[0m in \u001B[0;36mmean_absolute_error\u001B[1;34m(y_true, y_pred, sample_weight, multioutput)\u001B[0m\n\u001B[0;32m    185\u001B[0m     \"\"\"\n\u001B[0;32m    186\u001B[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001B[1;32m--> 187\u001B[1;33m         \u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmultioutput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    188\u001B[0m     )\n\u001B[0;32m    189\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001B[0m in \u001B[0;36m_check_reg_targets\u001B[1;34m(y_true, y_pred, multioutput, dtype)\u001B[0m\n\u001B[0;32m     89\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m     \u001B[0my_true\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mensure_2d\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 91\u001B[1;33m     \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mensure_2d\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     92\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0my_true\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    790\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    791\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 792\u001B[1;33m             \u001B[0m_assert_all_finite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_nan\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mforce_all_finite\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"allow-nan\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    793\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    794\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mensure_min_samples\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype)\u001B[0m\n\u001B[0;32m    114\u001B[0m             raise ValueError(\n\u001B[0;32m    115\u001B[0m                 msg_err.format(\n\u001B[1;32m--> 116\u001B[1;33m                     \u001B[0mtype_err\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmsg_dtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mmsg_dtype\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    117\u001B[0m                 )\n\u001B[0;32m    118\u001B[0m             )\n",
      "\u001B[1;31mValueError\u001B[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "\n",
    "# knn = RadiusNeighborsRegressor()\n",
    "# model = GridSearchCV(knn, params, cv=5)\n",
    "# model.fit(x_train, y_train)\n",
    "# print(model.best_params_)\n",
    "\n",
    "rmse_val = []  #to store rmse values for different k\n",
    "model = RadiusNeighborsRegressor()\n",
    "\n",
    "model.fit(x_train, y_train)  #fit the model\n",
    "print(model)\n",
    "# print(model.score(x_test, y_test))\n",
    "predictions = model.predict(x_test)  #make prediction on test set\n",
    "error = mean_absolute_error(y_test, predictions)\n",
    "rmse_val.append(error)  #store rmse values\n",
    "\n",
    "#plotting the rmse values against k values\n",
    "curve = pd.DataFrame(rmse_val)  #elbow curve\n",
    "curve.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omerk\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:470: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22660\\3643814689.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m#fit the model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mpredictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_test\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m#make prediction on test set\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0merror\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmean_squared_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"mse\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean_squared_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"mae\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmean_absolute_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001B[0m in \u001B[0;36mmean_squared_error\u001B[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001B[0m\n\u001B[0;32m    422\u001B[0m     \"\"\"\n\u001B[0;32m    423\u001B[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001B[1;32m--> 424\u001B[1;33m         \u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmultioutput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    425\u001B[0m     )\n\u001B[0;32m    426\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001B[0m in \u001B[0;36m_check_reg_targets\u001B[1;34m(y_true, y_pred, multioutput, dtype)\u001B[0m\n\u001B[0;32m     89\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m     \u001B[0my_true\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mensure_2d\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 91\u001B[1;33m     \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mensure_2d\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     92\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0my_true\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    790\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    791\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 792\u001B[1;33m             \u001B[0m_assert_all_finite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mallow_nan\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mforce_all_finite\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"allow-nan\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    793\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    794\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mensure_min_samples\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype)\u001B[0m\n\u001B[0;32m    114\u001B[0m             raise ValueError(\n\u001B[0;32m    115\u001B[0m                 msg_err.format(\n\u001B[1;32m--> 116\u001B[1;33m                     \u001B[0mtype_err\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmsg_dtype\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mmsg_dtype\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    117\u001B[0m                 )\n\u001B[0;32m    118\u001B[0m             )\n",
      "\u001B[1;31mValueError\u001B[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "model = RadiusNeighborsRegressor()\n",
    "model.fit(x_train, y_train)  #fit the model\n",
    "predictions = model.predict(x_test)  #make prediction on test set\n",
    "error = mean_squared_error(y_test, predictions)\n",
    "print(\"mse\", mean_squared_error(y_test, predictions))\n",
    "print(\"mae\", mean_absolute_error(y_test, predictions))\n",
    "print(\"RMSE\", mean_squared_error(y_test, predictions, squared=False))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(y_test, predictions))\n",
    "print(\"R2\", r2_score(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 35, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth': [35], \"n_estimators\": [200,250,300]}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "model = GridSearchCV(forest, params, cv=5)\n",
    "model.fit(x_train, y_train.ravel())\n",
    "print(model.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\omerk\\OneDrive - Y-Con B.V\\Google\\Thesis\\data\\archive\\venv\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 0.16792311775742388\n",
      "mae 0.19202321419129123\n",
      "RMSE 0.40978423317329316\n",
      "MAPE 17047297120386.2\n",
      "R2 0.660830182752026\n",
      "Variable: value_eur            Importance: 0.61\n",
      "Variable: potential            Importance: 0.04\n",
      "Variable: age                  Importance: 0.03\n",
      "Variable: international_reputation Importance: 0.03\n",
      "Variable: Unnamed: 0           Importance: 0.01\n",
      "Variable: nationality          Importance: 0.01\n",
      "Variable: club_name            Importance: 0.01\n",
      "Variable: league_name          Importance: 0.01\n",
      "Variable: wage_eur             Importance: 0.01\n",
      "Variable: attacking_heading_accuracy Importance: 0.01\n",
      "Variable: attacking_volleys    Importance: 0.01\n",
      "Variable: skill_dribbling      Importance: 0.01\n",
      "Variable: skill_curve          Importance: 0.01\n",
      "Variable: skill_fk_accuracy    Importance: 0.01\n",
      "Variable: skill_long_passing   Importance: 0.01\n",
      "Variable: skill_ball_control   Importance: 0.01\n",
      "Variable: movement_acceleration Importance: 0.01\n",
      "Variable: movement_sprint_speed Importance: 0.01\n",
      "Variable: movement_agility     Importance: 0.01\n",
      "Variable: movement_reactions   Importance: 0.01\n",
      "Variable: movement_balance     Importance: 0.01\n",
      "Variable: power_shot_power     Importance: 0.01\n",
      "Variable: power_jumping        Importance: 0.01\n",
      "Variable: power_stamina        Importance: 0.01\n",
      "Variable: power_strength       Importance: 0.01\n",
      "Variable: power_long_shots     Importance: 0.01\n",
      "Variable: mentality_aggression Importance: 0.01\n",
      "Variable: mentality_interceptions Importance: 0.01\n",
      "Variable: mentality_positioning Importance: 0.01\n",
      "Variable: mentality_vision     Importance: 0.01\n",
      "Variable: mentality_penalties  Importance: 0.01\n",
      "Variable: defending_sliding_tackle Importance: 0.01\n",
      "Variable: height_cm            Importance: 0.0\n",
      "Variable: weight_kg            Importance: 0.0\n",
      "Variable: league_rank          Importance: 0.0\n",
      "Variable: overall              Importance: 0.0\n",
      "Variable: preferred_foot       Importance: 0.0\n",
      "Variable: weak_foot            Importance: 0.0\n",
      "Variable: skill_moves          Importance: 0.0\n",
      "Variable: work_rate            Importance: 0.0\n",
      "Variable: team_position        Importance: 0.0\n",
      "Variable: attacking_crossing   Importance: 0.0\n",
      "Variable: attacking_finishing  Importance: 0.0\n",
      "Variable: attacking_short_passing Importance: 0.0\n",
      "Variable: defending_standing_tackle Importance: 0.0\n",
      "Variable: LW                   Importance: 0.0\n",
      "Variable: ST                   Importance: 0.0\n",
      "Variable: RW                   Importance: 0.0\n",
      "Variable: CF                   Importance: 0.0\n",
      "Variable: LM                   Importance: 0.0\n",
      "Variable: CM                   Importance: 0.0\n",
      "Variable: RM                   Importance: 0.0\n",
      "Variable: CAM                  Importance: 0.0\n",
      "Variable: CDM                  Importance: 0.0\n",
      "Variable: LB                   Importance: 0.0\n",
      "Variable: CB                   Importance: 0.0\n",
      "Variable: RB                   Importance: 0.0\n",
      "Variable: LWB                  Importance: 0.0\n",
      "Variable: RWB                  Importance: 0.0\n",
      "Variable: GK                   Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "feature_names = x_data.columns.values\n",
    "forest = RandomForestRegressor(max_depth=35, random_state=42, n_estimators=300)\n",
    "\n",
    "forest.fit(x_train, y_train)\n",
    "predictions = forest.predict(x_test)\n",
    "print(\"mse\", mean_squared_error(y_test, predictions))\n",
    "print(\"mae\", mean_absolute_error(y_test, predictions))\n",
    "print(\"RMSE\", mean_squared_error(y_test, predictions, squared=False))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(y_test, predictions))\n",
    "print(\"R2\", r2_score(y_test, predictions))\n",
    "\n",
    "# Get numerical feature importances\n",
    "importances = list(forest.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_names, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n",
    "# Print out the feature and importances\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse 2.9570194492389695e-12\n",
      "mae 1.3376936688051737e-06\n",
      "RMSE 1.7195986302736373e-06\n",
      "MAPE 612353795.0046529\n",
      "R2 0.2515632661383659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg = LinearRegression()\n",
    "\n",
    "linreg.fit(x_train, y_train)\n",
    "predictions = linreg.predict(x_test)\n",
    "print(\"mse\",mean_squared_error(y_test,predictions))\n",
    "print(\"mae\",mean_absolute_error(y_test,predictions))\n",
    "print(\"RMSE\", mean_squared_error(y_test, predictions, squared=False))\n",
    "print(\"MAPE\", mean_absolute_percentage_error(y_test, predictions))\n",
    "print(\"R2\", r2_score(y_test, predictions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}